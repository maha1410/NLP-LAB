{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab4. Computing Document Similarity using Doc2Vec Model\n",
    "### EXERCISE-1 \n",
    "### 1. Import dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5qfhdUf-x6pu"
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgoo7rqI6IRf"
   },
   "source": [
    "### 2. Create dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fIi4h3iFyTew"
   },
   "outputs": [],
   "source": [
    "data = [\"I love machine learning. Its awesome.\",\n",
    " \"I love coding in python\",\n",
    " \"I love building chatbots\",\n",
    " \"they chat amagingly well\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cs2eVjxezgZ8",
    "outputId": "99b39f77-554d-4eeb-dc4c-04b43385ec66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkWuAdXJ6RCI"
   },
   "source": [
    "### 3. Create TaggedDocument "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ecouUdGQzDef"
   },
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(d.lower()), \n",
    "tags=[str(i)]) for i, d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPLZ2-sY6UK2"
   },
   "source": [
    "### 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "m1MbYRjczk9u"
   },
   "outputs": [],
   "source": [
    "vec_size = 20\n",
    "alpha = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HW8UVLkbz7SJ",
    "outputId": "56bb4800-6844-44b1-d8e8-078fb0667fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(vector_size=vec_size,\n",
    " alpha=alpha, \n",
    " min_alpha=0.00025,\n",
    " min_count=1,\n",
    " dm =1)\n",
    "# build vocabulary\n",
    "model.build_vocab(tagged_data)\n",
    "# shuffle data\n",
    "tagged_data = utils.shuffle(tagged_data)\n",
    "# train Doc2Vec model\n",
    "model.train(tagged_data,\n",
    " total_examples=model.corpus_count,\n",
    " epochs=30)\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBrLIMpS6aMY"
   },
   "source": [
    "### 5. Find Similar documents for the given document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPJfIOYu0HFB",
    "outputId": "13ccb7d6-5cf1-438d-cb13-95120cb578f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [-0.00869065 -0.01238877  0.01076634  0.01837858 -0.01185473  0.0152639\n",
      "  0.00312291  0.00715544 -0.01393549 -0.02041687  0.00920063 -0.0127892\n",
      " -0.00577795 -0.00978915 -0.00954527  0.00275575  0.0105227  -0.01635379\n",
      "  0.02378107  0.00102777]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "#to find the vector of a document which is not in training data\n",
    "test_data = word_tokenize(\"I love chatbots\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-udHykqd0VfK",
    "outputId": "c7a85e49-04f3-4819-d052-daa073aa2cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3', 0.2867772579193115), ('0', 0.14935939013957977), ('2', -0.17948105931282043)]\n"
     ]
    }
   ],
   "source": [
    "similar_doc = model.docvecs.most_similar('1')\n",
    "print(similar_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVR94aCK0d_J",
    "outputId": "1c4e768a-c766-40db-c33e-c3d8c90f0e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.4631111e-03  2.0471280e-02  1.2875644e-02  2.3986014e-02\n",
      " -8.5967574e-03  7.7667716e-03  8.9874053e-03  2.4314741e-02\n",
      "  1.1871044e-02 -2.1266585e-02 -2.6052014e-03 -5.8996924e-03\n",
      "  1.7793141e-02 -5.5611712e-05  1.4491647e-02  7.6084463e-03\n",
      "  1.8754840e-03  2.2718612e-02 -1.9271666e-02  1.0655354e-02]\n"
     ]
    }
   ],
   "source": [
    "print(model.docvecs['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQuE6MF_6fmH"
   },
   "source": [
    "### EXERCISE-2 \n",
    "### Question1. Train the following documents using Doc2Vec model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-qTDrW121CUB"
   },
   "outputs": [],
   "source": [
    "docs=[\"the house had a tiny little mouse\",\n",
    "\"the cat saw the mouse\",\n",
    "\"the mouse ran away from the house\",\n",
    "\"the cat finally ate the mouse\",\n",
    "\"the end of the mouse story\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "XXoZ_aCB1Rmh"
   },
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(d.lower()), \n",
    "tags=[str(i)]) for i, d in enumerate(docs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "oJIh1uEE1abA"
   },
   "outputs": [],
   "source": [
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "# create model\n",
    "model = Doc2Vec(vector_size=vec_size, alpha=alpha, min_alpha=0.00025,min_count=1,dm =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "nvwajetm1mD4"
   },
   "outputs": [],
   "source": [
    "model.build_vocab(tagged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "rl5t9Ej52xBV"
   },
   "outputs": [],
   "source": [
    "tagged_data = utils.shuffle(tagged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hz8e9P4O2zDN",
    "outputId": "f10436f9-f78b-4fe5-9e7d-b30e18355e65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "model.train(tagged_data,total_examples=model.corpus_count,epochs=30)\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qG3NineJ6mPv"
   },
   "source": [
    "### Question2. Find the most similar TWO documents for the query document “cat stayed in the house”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "EEjd9-uq25e8"
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model= Doc2Vec.load(\"d2v.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EW9SpSnW5ANR",
    "outputId": "6f8e0ad2-3c97-4858-d989-cca6815069a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [-0.01994306 -0.00365496 -0.02367386 -0.00445433  0.00579851  0.01591771\n",
      " -0.01106277  0.00164189 -0.00461278 -0.00962676  0.00456066 -0.02325257\n",
      "  0.01938994 -0.00737341 -0.02321905 -0.02015355 -0.0067498  -0.00298602\n",
      "  0.00556086 -0.00357911]\n"
     ]
    }
   ],
   "source": [
    "test_data = word_tokenize(\"cat stayed in the house\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inA4xvk63OCR",
    "outputId": "d1b9551b-0d3d-4a1c-b79e-ebae05b7ee4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3', 0.0957995355129242), ('0', 0.0746668130159378), ('4', 0.0397355742752552), ('1', -0.15176615118980408)]\n"
     ]
    }
   ],
   "source": [
    "similar_doc = model.docvecs.most_similar('2')\n",
    "print(similar_doc)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab 4 nlp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
