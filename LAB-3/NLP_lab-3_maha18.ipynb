{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab3. Computing Document Similarity using VSM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE-1: Print TFIDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.7071067811865476\n",
      "  (0, 2)\t0.7071067811865476\n",
      "  (1, 3)\t0.5773502691896257\n",
      "  (1, 0)\t0.5773502691896257\n",
      "  (1, 2)\t0.5773502691896257\n",
      "  (2, 1)\t0.7071067811865476\n",
      "  (2, 3)\t0.7071067811865476\n",
      "  (3, 1)\t1.0\n",
      "   good movie      like     movie       not\n",
      "0    0.707107  0.000000  0.707107  0.000000\n",
      "1    0.577350  0.000000  0.577350  0.577350\n",
      "2    0.000000  0.707107  0.000000  0.707107\n",
      "3    0.000000  1.000000  0.000000  0.000000\n",
      "4    0.000000  0.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "docs = [\n",
    " \"good movie\", \"not a good movie\", \"did not like\", \n",
    " \"i like it\", \"good one\" ] \n",
    "# using default tokenizer in TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "features = tfidf.fit_transform(docs)\n",
    "print(features)\n",
    "# Pretty printing\n",
    "df = pd.DataFrame(\n",
    " features.todense(),\n",
    " columns=tfidf.get_feature_names())\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE-2:\n",
    "#### 1. Change the values of min_df and ngram_range and observe various outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1.0\n",
      "  (1, 3)\t0.7071067811865476\n",
      "  (1, 4)\t0.7071067811865476\n",
      "  (2, 4)\t0.5317722537280788\n",
      "  (2, 0)\t0.6591180018251055\n",
      "  (2, 2)\t0.5317722537280788\n",
      "  (3, 2)\t0.6279137616509933\n",
      "  (3, 1)\t0.7782829228046183\n",
      "  (4, 5)\t1.0\n",
      "        did        it      like     movie       not  one\n",
      "0  0.000000  0.000000  0.000000  1.000000  0.000000  0.0\n",
      "1  0.000000  0.000000  0.000000  0.707107  0.707107  0.0\n",
      "2  0.659118  0.000000  0.531772  0.000000  0.531772  0.0\n",
      "3  0.000000  0.778283  0.627914  0.000000  0.000000  0.0\n",
      "4  0.000000  0.000000  0.000000  0.000000  0.000000  1.0\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    " \"good movie\", \"not a good movie\", \"did not like\", \n",
    " \"i like it\", \"good one\" ] \n",
    "# using default tokenizer in TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=1, max_df=0.5, ngram_range=(2, 1))\n",
    "features = tfidf.fit_transform(docs)\n",
    "print(features)\n",
    "# Pretty printing\n",
    "df = pd.DataFrame(\n",
    " features.todense(),\n",
    " columns=tfidf.get_feature_names())\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE-3: Compute Cosine Similarity between 2 Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81649658]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "# cosine score between 1st and 2nd doc\n",
    "doc1 = features[0:1]\n",
    "doc2 = features[1:2]\n",
    "score = linear_kernel(doc1, doc2)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.81649658 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "scores = linear_kernel(doc1, features)    # cosine score between 1st and all other docs\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.81649658 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "query = \"I like this good movie\"        # Cosine Similarity for a new doc\n",
    "qfeature = tfidf.transform([query])\n",
    "scores2 = linear_kernel(doc1, features)\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE-4: Find Top-N similar documents \n",
    "#### Question-1. Consider the following documents and compute TFIDF values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.5233582502695435\n",
      "  (0, 13)\t0.5233582502695435\n",
      "  (0, 6)\t0.5233582502695435\n",
      "  (0, 7)\t0.4222421409859579\n",
      "  (1, 11)\t0.7782829228046183\n",
      "  (1, 2)\t0.6279137616509933\n",
      "  (2, 5)\t0.5233582502695435\n",
      "  (2, 1)\t0.5233582502695435\n",
      "  (2, 10)\t0.5233582502695435\n",
      "  (2, 7)\t0.4222421409859579\n",
      "  (3, 0)\t0.6141889663426562\n",
      "  (3, 4)\t0.6141889663426562\n",
      "  (3, 2)\t0.49552379079705033\n",
      "  (4, 12)\t0.5773502691896258\n",
      "  (4, 9)\t0.5773502691896258\n",
      "  (4, 3)\t0.5773502691896258\n",
      "        ate      away       cat      end   finally      from       had  \\\n",
      "0  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.523358   \n",
      "1  0.000000  0.000000  0.627914  0.00000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.523358  0.000000  0.00000  0.000000  0.523358  0.000000   \n",
      "3  0.614189  0.000000  0.495524  0.00000  0.614189  0.000000  0.000000   \n",
      "4  0.000000  0.000000  0.000000  0.57735  0.000000  0.000000  0.000000   \n",
      "\n",
      "      house    little       of       ran       saw    story      tiny  \n",
      "0  0.422242  0.523358  0.00000  0.000000  0.000000  0.00000  0.523358  \n",
      "1  0.000000  0.000000  0.00000  0.000000  0.778283  0.00000  0.000000  \n",
      "2  0.422242  0.000000  0.00000  0.523358  0.000000  0.00000  0.000000  \n",
      "3  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000  0.000000  \n",
      "4  0.000000  0.000000  0.57735  0.000000  0.000000  0.57735  0.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# this is a very toy example, do not try this at home unless you want to understand the usage differences \n",
    "docs=[\"the house had a tiny little mouse\", \n",
    "\"the cat saw the mouse\", \n",
    "\"the mouse ran away from the house\", \n",
    "\"the cat finally ate the mouse\", \n",
    "\"the end of the mouse story\"\n",
    "]\n",
    "# using default tokenizer in TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=1, max_df=0.5, ngram_range=(1, 1))\n",
    "features = tfidf.fit_transform(docs)\n",
    "print(features)\n",
    "# Pretty printing\n",
    "df = pd.DataFrame(\n",
    " features.todense(),\n",
    " columns=tfidf.get_feature_names())\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-2. Compute cosine similarity between 3rddocument (“the mouse ran away from the  house”) with all other documents. Which is the most similar document?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[\"the house had a tiny little mouse\", \n",
    "\"the cat saw the mouse\", \n",
    "\"the mouse ran away from the house\", \n",
    "\"the cat finally ate the mouse\", \n",
    "\"the end of the mouse story\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t0.7071067811865476\n",
      "  (0, 1)\t0.7071067811865476\n",
      "  (1, 2)\t0.7071067811865476\n",
      "  (1, 0)\t0.7071067811865476\n",
      "  (2, 3)\t0.7071067811865476\n",
      "  (2, 1)\t0.7071067811865476\n",
      "  (3, 2)\t0.7071067811865476\n",
      "  (3, 0)\t0.7071067811865476\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "features = tfidf.fit_transform(docs)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "docs = features[0:3]\n",
    "scores = linear_kernel(docs, features)    # cosine score between 1st and all other docs\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
